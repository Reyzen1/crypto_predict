# File: temp/fix_scaler_issue.py
# Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø§ØµÙ„Ø§Ø­ ÙÙˆØ±ÛŒ Ù…Ø´Ú©Ù„ MinMaxScaler

import sys
import os
sys.path.append('.')

def apply_scaler_fix():
    """Ø§ØµÙ„Ø§Ø­ Ù…Ø´Ú©Ù„ MinMaxScaler Ø¯Ø± lstm_predictor.py"""
    
    lstm_file_path = 'backend/app/ml/models/lstm_predictor.py'
    
    try:
        # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ ÙØ¹Ù„ÛŒ
        with open(lstm_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print("ðŸ”§ Ø§ØµÙ„Ø§Ø­ Ù…Ø´Ú©Ù„ MinMaxScaler...")
        
        # Ø§ØµÙ„Ø§Ø­ 1: Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ø±Ø¯Ù† fillna deprecated
        old_fillna = "data[feature_columns] = data[feature_columns].fillna(method='ffill').fillna(method='bfill')"
        new_fillna = """# Handle missing values with modern pandas methods
        for col in feature_columns:
            if col in data.columns:
                data[col] = data[col].ffill().bfill()"""
        
        if old_fillna in content:
            content = content.replace(old_fillna, new_fillna)
            print("âœ… Ø§ØµÙ„Ø§Ø­ fillna deprecated")
        
        # Ø§ØµÙ„Ø§Ø­ 2: Ø¨Ù‡Ø¨ÙˆØ¯ prepare_data method
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø´Ø±ÙˆØ¹ method prepare_data
        start_marker = "def prepare_data("
        end_marker = "return X, y, self.scaler, self.feature_scaler"
        
        start_pos = content.find(start_marker)
        if start_pos != -1:
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§Ù†ØªÙ‡Ø§ÛŒ method
            end_pos = content.find(end_marker, start_pos)
            if end_pos != -1:
                end_pos = content.find('\n', end_pos) + 1
                
                # method Ø¬Ø¯ÛŒØ¯
                new_prepare_data = '''def prepare_data(
        self, 
        data: pd.DataFrame, 
        target_column: str = 'close_price',
        feature_columns: Optional[List[str]] = None
    ) -> Tuple[np.ndarray, np.ndarray, Any, Any]:
        """
        Prepare data for LSTM training - FIXED VERSION
        
        Args:
            data: DataFrame with price and indicator data
            target_column: Column name for prediction target
            feature_columns: List of feature column names
            
        Returns:
            Tuple of (X, y, target_scaler, feature_scaler)
        """
        if feature_columns is None:
            # Ø§Ù†ØªØ®Ø§Ø¨ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø­ØªÙ…Ø§Ù‹ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ù†Ø¯
            available_features = []
            potential_features = [
                'close_price', 'volume', 'open_price', 'high_price', 'low_price',
                'rsi', 'sma_20', 'ema_12', 'macd', 'market_cap'
            ]
            
            for col in potential_features:
                if col in data.columns:
                    available_features.append(col)
            
            feature_columns = available_features[:self.n_features]  # Ø­Ø¯Ø§Ú©Ø«Ø± n_features Ø³ØªÙˆÙ†
            
            if len(feature_columns) < 2:
                # Ø­Ø¯Ø§Ù‚Ù„ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡
                feature_columns = ['close_price', 'volume'] if 'volume' in data.columns else ['close_price', 'open_price']
        
        # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
        missing_cols = [col for col in feature_columns if col not in data.columns]
        if missing_cols:
            logger.warning(f"Missing columns {missing_cols}, removing from features")
            feature_columns = [col for col in feature_columns if col in data.columns]
        
        if not feature_columns:
            raise ValueError("No valid feature columns found")
        
        if target_column not in data.columns:
            raise ValueError(f"Target column '{target_column}' not found in data")
        
        # Ù…Ø±ØªØ¨ Ú©Ø±Ø¯Ù† Ø¨Ø± Ø§Ø³Ø§Ø³ timestamp
        if 'timestamp' in data.columns:
            data = data.sort_values('timestamp').copy()
        
        # Handle missing values - Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø±ÙˆØ´ Ø¬Ø¯ÛŒØ¯ pandas
        logger.info(f"Using feature columns: {feature_columns}")
        data_clean = data.copy()
        
        # Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ø±Ø¯Ù† fillna Ù‚Ø¯ÛŒÙ…ÛŒ Ø¨Ø§ Ø±ÙˆØ´ Ø¬Ø¯ÛŒØ¯ pandas
        for col in feature_columns + [target_column]:
            if col in data_clean.columns:
                # Forward fill then backward fill
                data_clean[col] = data_clean[col].ffill().bfill()
        
        # Ø­Ø°Ù NaN Ù‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒ Ù…Ø§Ù†Ø¯Ù‡
        data_clean = data_clean.dropna(subset=feature_columns + [target_column])
        
        if len(data_clean) < self.sequence_length + 1:
            raise ValueError(f"Insufficient data after cleaning: {len(data_clean)} < {self.sequence_length + 1}")
        
        # Extract features and target
        features = data_clean[feature_columns].values
        target = data_clean[target_column].values.reshape(-1, 1)
        
        logger.info(f"Data shape before scaling: features {features.shape}, target {target.shape}")
        
        # FIXED: Initialize and fit scalers properly
        if self.feature_scaler is None:
            self.feature_scaler = RobustScaler()  # More robust to outliers
        
        if self.scaler is None:
            self.scaler = MinMaxScaler(feature_range=(0, 1))
        
        # Fit and transform features
        features_scaled = self.feature_scaler.fit_transform(features)
        
        # Fit and transform target
        target_scaled = self.scaler.fit_transform(target)
        
        # Update n_features based on actual features used
        self.n_features = features_scaled.shape[1]
        
        # Create sequences for LSTM
        X, y = self._create_sequences(features_scaled, target_scaled.flatten())
        
        logger.info(f"âœ… Data prepared successfully: X shape {X.shape}, y shape {y.shape}")
        logger.info(f"âœ… Scalers fitted: feature_scaler={self.feature_scaler is not None}, target_scaler={self.scaler is not None}")
        
        return X, y, self.scaler, self.feature_scaler
'''
                
                # Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ø±Ø¯Ù† method Ù‚Ø¯ÛŒÙ…ÛŒ Ø¨Ø§ Ø¬Ø¯ÛŒØ¯
                content = content[:start_pos] + new_prepare_data + content[end_pos:]
                print("âœ… Ø§ØµÙ„Ø§Ø­ prepare_data method")
        
        # Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡
        with open(lstm_file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print("âœ… ÙØ§ÛŒÙ„ lstm_predictor.py Ø§ØµÙ„Ø§Ø­ Ø´Ø¯")
        return True
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ØµÙ„Ø§Ø­ ÙØ§ÛŒÙ„: {e}")
        return False

def test_fix():
    """ØªØ³Øª Ø§ØµÙ„Ø§Ø­ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡"""
    print("\nðŸ§ª ØªØ³Øª Ø§ØµÙ„Ø§Ø­...")
    
    try:
        # Import Ú©Ù„Ø§Ø³ Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡
        from app.ml.models.lstm_predictor import LSTMPredictor
        
        # ØªØ³Øª Ø§ÛŒØ¬Ø§Ø¯ instance
        lstm = LSTMPredictor(sequence_length=10, n_features=3)
        print("âœ… LSTMPredictor instance Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
        
        # ØªØ³Øª dummy data
        import pandas as pd
        import numpy as np
        
        test_data = pd.DataFrame({
            'timestamp': pd.date_range('2023-01-01', periods=50, freq='1H'),
            'close_price': np.random.uniform(45000, 55000, 50),
            'volume': np.random.uniform(1000, 10000, 50),
            'open_price': np.random.uniform(44000, 54000, 50)
        })
        
        # ØªØ³Øª prepare_data
        X, y, target_scaler, feature_scaler = lstm.prepare_data(test_data)
        print(f"âœ… prepare_data Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯: X shape {X.shape}, y shape {y.shape}")
        print(f"âœ… Scalers fitted: target={target_scaler is not None}, feature={feature_scaler is not None}")
        
        return True
        
    except Exception as e:
        print(f"âŒ ØªØ³Øª Ù†Ø§Ù…ÙˆÙÙ‚: {e}")
        return False

if __name__ == "__main__":
    print("ðŸš€ Ø´Ø±ÙˆØ¹ Ø§ØµÙ„Ø§Ø­ Ù…Ø´Ú©Ù„ MinMaxScaler")
    print("=" * 50)
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ø§ØµÙ„Ø§Ø­
    if apply_scaler_fix():
        # ØªØ³Øª Ø§ØµÙ„Ø§Ø­
        if test_fix():
            print("\nðŸŽ‰ Ø§ØµÙ„Ø§Ø­ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯!")
            print("\nØ­Ø§Ù„Ø§ Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯ Ø¯ÙˆØ¨Ø§Ø±Ù‡ ØªØ³Øª Ú©Ù†ÛŒØ¯:")
            print("python temp/test_complete_ml_pipeline.py")
        else:
            print("\nâš ï¸ Ø§ØµÙ„Ø§Ø­ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ Ø§Ù…Ø§ ØªØ³Øª Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯")
    else:
        print("\nâŒ Ø§ØµÙ„Ø§Ø­ Ù†Ø§Ù…ÙˆÙÙ‚")