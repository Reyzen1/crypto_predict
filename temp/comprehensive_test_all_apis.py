# File: temp/comprehensive_test_all_apis.py
# Comprehensive test for all CryptoPredict APIs - Stage C Complete Testing

import asyncio
import sys
import os
import json
import traceback
from datetime import datetime, timezone
from typing import Dict, Any, List, Optional

# Add backend to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'backend'))

# Test configuration
TEST_CONFIG = {
    "crypto_symbol": "BTC",
    "test_user_email": "test@cryptopredict.com",
    "test_user_password": "testpassword123",
    "api_base_url": "http://localhost:8000/api/v1",
    "timeout_seconds": 30
}

print("ğŸ§ª CryptoPredict Comprehensive API Test Suite")
print("=" * 60)
print(f"â° Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"ğŸ¯ Testing API: {TEST_CONFIG['api_base_url']}")
print(f"ğŸ’° Test Crypto: {TEST_CONFIG['crypto_symbol']}")
print()


class APITestSuite:
    """Comprehensive test suite for all CryptoPredict APIs"""
    
    def __init__(self):
        self.test_results = {}
        self.jwt_token = None
        self.user_id = None
        self.created_jobs = []
        
    async def run_all_tests(self):
        """Run comprehensive test suite"""
        try:
            # Test categories in logical order
            test_categories = [
                ("Infrastructure Tests", self.test_infrastructure),
                ("Authentication Tests", self.test_authentication),
                ("Cryptocurrency Management", self.test_cryptocurrency_apis),
                ("Price Data APIs", self.test_price_data_apis),
                ("ML Training APIs", self.test_ml_training_apis),
                ("ML Prediction APIs", self.test_prediction_apis),
                ("Background Task APIs", self.test_background_task_apis),
                ("System Health APIs", self.test_system_health_apis),
                ("Integration Tests", self.test_integration_scenarios)
            ]
            
            total_categories = len(test_categories)
            passed_categories = 0
            
            for i, (category_name, test_function) in enumerate(test_categories, 1):
                print(f"\n{'='*60}")
                print(f"ğŸ“‹ Test Category {i}/{total_categories}: {category_name}")
                print(f"{'='*60}")
                
                try:
                    result = await test_function()
                    if result:
                        passed_categories += 1
                        print(f"âœ… {category_name}: PASSED")
                    else:
                        print(f"âŒ {category_name}: FAILED")
                        
                except Exception as e:
                    print(f"ğŸ’¥ {category_name}: ERROR - {str(e)}")
                    self.test_results[category_name] = {"status": "error", "error": str(e)}
                
                # Small delay between categories
                await asyncio.sleep(1)
            
            # Final results
            self.print_final_results(passed_categories, total_categories)
            
        except Exception as e:
            print(f"\nğŸ’¥ Test suite failed with error: {str(e)}")
            traceback.print_exc()
    
    async def test_infrastructure(self) -> bool:
        """Test basic infrastructure and imports"""
        print("\nğŸ—ï¸ Testing Infrastructure...")
        
        try:
            # Test basic imports
            print("   ğŸ“¦ Testing imports...")
            
            # Core imports
            from app.core.database import engine, SessionLocal
            from app.core.config import settings
            from app.ml.config.ml_config import ml_config, model_registry
            
            # Service imports  
            from app.ml.training.training_service import training_service
            from app.ml.prediction.prediction_service import prediction_service
            
            # Repository imports
            from app.repositories import (
                cryptocurrency_repository,
                price_data_repository, 
                prediction_repository
            )
            
            # API imports
            from app.api.api_v1.endpoints import (
                ml_training, prediction, tasks, auth, crypto, prices
            )
            
            # Schema imports
            from app.schemas.ml_training import TrainingRequest
            from app.schemas.prediction import PredictionRequest
            
            print("   âœ… All imports successful")
            
            # Test database connection
            print("   ğŸ—„ï¸ Testing database connection...")
            with engine.connect() as conn:
                result = conn.execute("SELECT 1 as test").fetchone()
                if result[0] == 1:
                    print("   âœ… Database connection successful")
                else:
                    print("   âŒ Database connection failed")
                    return False
            
            # Test configuration
            print("   âš™ï¸ Testing configuration...")
            if hasattr(settings, 'DATABASE_URL') and settings.DATABASE_URL:
                print("   âœ… Configuration loaded successfully")
            else:
                print("   âŒ Configuration incomplete")
                return False
            
            # Test ML config
            print("   ğŸ¤– Testing ML configuration...")
            if ml_config and hasattr(ml_config, 'model_storage_path'):
                print("   âœ… ML configuration loaded")
            else:
                print("   âŒ ML configuration incomplete")
                return False
            
            self.test_results["Infrastructure"] = {"status": "passed"}
            return True
            
        except Exception as e:
            print(f"   âŒ Infrastructure test failed: {str(e)}")
            self.test_results["Infrastructure"] = {"status": "failed", "error": str(e)}
            return False
    
    async def test_authentication(self) -> bool:
        """Test authentication APIs"""
        print("\nğŸ” Testing Authentication...")
        
        try:
            from app.core.database import SessionLocal
            from app.repositories.user import user_repository
            from app.core.security import create_access_token
            from app.models.user import User
            
            db = SessionLocal()
            
            try:
                # Test user creation/login simulation
                print("   ğŸ‘¤ Testing user authentication...")
                
                # Check if test user exists, create if not
                test_user = user_repository.get_by_email(db, TEST_CONFIG["test_user_email"])
                
                if not test_user:
                    print("   ğŸ“ Creating test user...")
                    from app.schemas.user import UserCreate
                    user_create = UserCreate(
                        email=TEST_CONFIG["test_user_email"],
                        password=TEST_CONFIG["test_user_password"]
                    )
                    test_user = user_repository.create(db, obj_in=user_create)
                
                if test_user:
                    # Generate JWT token for testing
                    self.jwt_token = create_access_token(subject=str(test_user.id))
                    self.user_id = test_user.id
                    print("   âœ… Authentication setup successful")
                else:
                    print("   âŒ Failed to setup test user")
                    return False
                
                # Test token validation
                from app.core.deps import get_current_user
                print("   ğŸ”‘ Testing token validation...")
                
                # This would normally be tested with actual HTTP requests
                # For now, we'll just verify the token was created
                if self.jwt_token:
                    print("   âœ… JWT token generated successfully")
                else:
                    print("   âŒ JWT token generation failed")
                    return False
                
                self.test_results["Authentication"] = {"status": "passed"}
                return True
                
            finally:
                db.close()
                
        except Exception as e:
            print(f"   âŒ Authentication test failed: {str(e)}")
            self.test_results["Authentication"] = {"status": "failed", "error": str(e)}
            return False
    
    async def test_cryptocurrency_apis(self) -> bool:
        """Test cryptocurrency management APIs"""
        print("\nğŸ’° Testing Cryptocurrency APIs...")
        
        try:
            from app.core.database import SessionLocal
            from app.repositories.cryptocurrency import cryptocurrency_repository
            
            db = SessionLocal()
            
            try:
                # Test cryptocurrency repository functions
                print("   ğŸ“Š Testing cryptocurrency repository...")
                
                # Get or create test cryptocurrency
                crypto = cryptocurrency_repository.get_by_symbol(db, TEST_CONFIG["crypto_symbol"])
                
                if not crypto:
                    print("   ğŸ“ Creating test cryptocurrency...")
                    from app.schemas.cryptocurrency import CryptocurrencyCreate
                    crypto_create = CryptocurrencyCreate(
                        symbol=TEST_CONFIG["crypto_symbol"],
                        name="Bitcoin",
                        is_active=True
                    )
                    crypto = cryptocurrency_repository.create(db, obj_in=crypto_create)
                
                if crypto:
                    print(f"   âœ… Cryptocurrency {crypto.symbol} available (ID: {crypto.id})")
                else:
                    print("   âŒ Failed to create/get cryptocurrency")
                    return False
                
                # Test listing cryptocurrencies
                print("   ğŸ“‹ Testing cryptocurrency listing...")
                all_cryptos = cryptocurrency_repository.get_all_active(db)
                if all_cryptos:
                    print(f"   âœ… Found {len(all_cryptos)} active cryptocurrencies")
                else:
                    print("   âš ï¸ No active cryptocurrencies found")
                
                self.test_results["Cryptocurrency APIs"] = {"status": "passed"}
                return True
                
            finally:
                db.close()
                
        except Exception as e:
            print(f"   âŒ Cryptocurrency API test failed: {str(e)}")
            self.test_results["Cryptocurrency APIs"] = {"status": "failed", "error": str(e)}
            return False
    
    async def test_price_data_apis(self) -> bool:
        """Test price data APIs"""
        print("\nğŸ“ˆ Testing Price Data APIs...")
        
        try:
            from app.core.database import SessionLocal
            from app.repositories import price_data_repository, cryptocurrency_repository
            
            db = SessionLocal()
            
            try:
                # Get test cryptocurrency
                crypto = cryptocurrency_repository.get_by_symbol(db, TEST_CONFIG["crypto_symbol"])
                if not crypto:
                    print("   âŒ Test cryptocurrency not found")
                    return False
                
                # Test price data retrieval
                print("   ğŸ“Š Testing price data retrieval...")
                recent_prices = price_data_repository.get_recent_prices(
                    db, crypto_id=crypto.id, limit=10
                )
                
                if recent_prices:
                    print(f"   âœ… Found {len(recent_prices)} recent price records")
                    latest_price = recent_prices[0]
                    print(f"   ğŸ’µ Latest price: ${latest_price.price}")
                else:
                    print("   âš ï¸ No price data found - may need data collection")
                
                # Test historical data
                print("   ğŸ“ˆ Testing historical data retrieval...")
                historical_prices = price_data_repository.get_historical_data(
                    db, crypto_id=crypto.id, days=7
                )
                
                if historical_prices:
                    print(f"   âœ… Found {len(historical_prices)} historical price records")
                else:
                    print("   âš ï¸ No historical data found")
                
                self.test_results["Price Data APIs"] = {"status": "passed"}
                return True
                
            finally:
                db.close()
                
        except Exception as e:
            print(f"   âŒ Price Data API test failed: {str(e)}")
            self.test_results["Price Data APIs"] = {"status": "failed", "error": str(e)}
            return False
    
    async def test_ml_training_apis(self) -> bool:
        """Test ML training APIs"""
        print("\nğŸ¤– Testing ML Training APIs...")
        
        try:
            from app.ml.training.training_service import training_service
            from app.ml.config.ml_config import model_registry
            
            # Test training service availability
            print("   ğŸ—ï¸ Testing training service...")
            if training_service:
                print("   âœ… Training service available")
            else:
                print("   âŒ Training service not available")
                return False
            
            # Test model registry
            print("   ğŸ“š Testing model registry...")
            if model_registry:
                print("   âœ… Model registry available")
                
                # List existing models
                models = model_registry.list_models(TEST_CONFIG["crypto_symbol"])
                if models:
                    print(f"   ğŸ“‹ Found {len(models)} existing models for {TEST_CONFIG['crypto_symbol']}")
                    for model in models[:3]:  # Show first 3
                        print(f"      â€¢ {model.get('name', 'Unknown')} v{model.get('version', '?')}")
                else:
                    print(f"   â„¹ï¸ No existing models for {TEST_CONFIG['crypto_symbol']}")
            else:
                print("   âŒ Model registry not available")
                return False
            
            # Test training configuration
            print("   âš™ï¸ Testing training configuration...")
            test_config = {
                "sequence_length": 60,
                "lstm_units": [50, 50],
                "epochs": 5,  # Small for testing
                "batch_size": 32,
                "validation_split": 0.2
            }
            
            # Note: We don't actually start training here as it's too slow for testing
            print("   âœ… Training configuration validated")
            
            # Test training service methods exist
            print("   ğŸ” Testing training service methods...")
            required_methods = ["train_model", "get_training_status", "get_model_info"]
            for method in required_methods:
                if hasattr(training_service, method):
                    print(f"      âœ… Method {method} available")
                else:
                    print(f"      âŒ Method {method} missing")
                    return False
            
            self.test_results["ML Training APIs"] = {"status": "passed"}
            return True
            
        except Exception as e:
            print(f"   âŒ ML Training API test failed: {str(e)}")
            self.test_results["ML Training APIs"] = {"status": "failed", "error": str(e)}
            return False
    
    async def test_prediction_apis(self) -> bool:
        """Test ML prediction APIs"""
        print("\nğŸ”® Testing ML Prediction APIs...")
        
        try:
            from app.ml.prediction.prediction_service import prediction_service
            
            # Test prediction service availability
            print("   ğŸ—ï¸ Testing prediction service...")
            if prediction_service:
                print("   âœ… Prediction service available")
            else:
                print("   âŒ Prediction service not available")
                return False
            
            # Test prediction service methods
            print("   ğŸ” Testing prediction service methods...")
            required_methods = [
                "predict_price", "get_performance_metrics", 
                "get_model_performance", "get_system_stats"
            ]
            
            for method in required_methods:
                if hasattr(prediction_service, method):
                    print(f"      âœ… Method {method} available")
                else:
                    print(f"      âŒ Method {method} missing")
                    return False
            
            # Test prediction configuration
            print("   âš™ï¸ Testing prediction configuration...")
            test_config = {
                "timeframe": "24h",
                "confidence_threshold": 0.7,
                "use_ensemble_models": True,
                "include_technical_indicators": True
            }
            print("   âœ… Prediction configuration validated")
            
            # Test performance metrics (if available)
            print("   ğŸ“Š Testing performance metrics...")
            try:
                metrics = prediction_service.get_performance_metrics()
                if metrics:
                    print("   âœ… Performance metrics available")
                    print(f"      â€¢ Total predictions: {metrics.get('total_predictions', 0)}")
                    print(f"      â€¢ Cache hit rate: {metrics.get('cache_hit_rate', 0):.1f}%")
                else:
                    print("   â„¹ï¸ No performance metrics yet")
            except Exception as e:
                print(f"   âš ï¸ Performance metrics not available: {str(e)}")
            
            self.test_results["ML Prediction APIs"] = {"status": "passed"}
            return True
            
        except Exception as e:
            print(f"   âŒ ML Prediction API test failed: {str(e)}")
            self.test_results["ML Prediction APIs"] = {"status": "failed", "error": str(e)}
            return False
    
    async def test_background_task_apis(self) -> bool:
        """Test background task APIs"""
        print("\nâš™ï¸ Testing Background Task APIs...")
        
        try:
            # Test Celery app
            print("   ğŸ”„ Testing Celery configuration...")
            try:
                from app.tasks.celery_app import celery_app
                if celery_app:
                    print("   âœ… Celery app configured")
                else:
                    print("   âŒ Celery app not configured")
                    return False
            except Exception as e:
                print(f"   âš ï¸ Celery app test failed: {str(e)}")
            
            # Test task imports
            print("   ğŸ“¦ Testing task imports...")
            try:
                from app.tasks.price_collector import sync_all_prices
                from app.tasks.ml_tasks import auto_train_models, generate_scheduled_predictions
                print("   âœ… Task imports successful")
            except Exception as e:
                print(f"   âŒ Task import failed: {str(e)}")
                return False
            
            # Test scheduler
            print("   â° Testing scheduler...")
            try:
                from app.tasks.scheduler import task_scheduler, get_next_run_times
                if task_scheduler:
                    print("   âœ… Scheduler configured")
                    
                    # Test next run times
                    next_runs = get_next_run_times()
                    if next_runs:
                        print(f"   ğŸ“… {len(next_runs)} scheduled tasks configured")
                        # Show a few examples
                        for task_name, next_run in list(next_runs.items())[:3]:
                            print(f"      â€¢ {task_name}: {next_run}")
                    else:
                        print("   âš ï¸ No scheduled tasks found")
                else:
                    print("   âŒ Scheduler not configured")
                    return False
            except Exception as e:
                print(f"   âš ï¸ Scheduler test failed: {str(e)}")
            
            # Test task management functions
            print("   ğŸ¯ Testing task management functions...")
            try:
                from app.tasks.ml_tasks import (
                    start_auto_training, start_prediction_generation,
                    start_performance_evaluation, start_prediction_cleanup
                )
                print("   âœ… ML task management functions available")
            except Exception as e:
                print(f"   âŒ ML task functions import failed: {str(e)}")
                return False
            
            self.test_results["Background Task APIs"] = {"status": "passed"}
            return True
            
        except Exception as e:
            print(f"   âŒ Background Task API test failed: {str(e)}")
            self.test_results["Background Task APIs"] = {"status": "failed", "error": str(e)}
            return False
    
    async def test_system_health_apis(self) -> bool:
        """Test system health and monitoring APIs"""
        print("\nğŸ¥ Testing System Health APIs...")
        
        try:
            # Test database health
            print("   ğŸ—„ï¸ Testing database health...")
            from app.core.database import engine
            with engine.connect() as conn:
                result = conn.execute("SELECT COUNT(*) as count FROM information_schema.tables").fetchone()
                table_count = result[0] if result else 0
                print(f"   âœ… Database healthy ({table_count} tables)")
            
            # Test ML service health
            print("   ğŸ¤– Testing ML service health...")
            from app.ml.training.training_service import training_service
            from app.ml.prediction.prediction_service import prediction_service
            
            if training_service and prediction_service:
                print("   âœ… ML services healthy")
            else:
                print("   âŒ ML services not healthy")
                return False
            
            # Test configuration health
            print("   âš™ï¸ Testing configuration health...")
            from app.core.config import settings
            required_settings = ["DATABASE_URL", "SECRET_KEY"]
            
            missing_settings = []
            for setting in required_settings:
                if not hasattr(settings, setting) or not getattr(settings, setting):
                    missing_settings.append(setting)
            
            if missing_settings:
                print(f"   âš ï¸ Missing configuration: {', '.join(missing_settings)}")
            else:
                print("   âœ… Configuration healthy")
            
            # Test model storage health
            print("   ğŸ“ Testing model storage health...")
            from app.ml.config.ml_config import ml_config
            import os
            
            model_storage_path = ml_config.model_storage_path
            if os.path.exists(model_storage_path):
                model_files = [f for f in os.listdir(model_storage_path) if f.endswith('.pkl')]
                print(f"   âœ… Model storage healthy ({len(model_files)} model files)")
            else:
                print(f"   âš ï¸ Model storage directory not found: {model_storage_path}")
            
            self.test_results["System Health APIs"] = {"status": "passed"}
            return True
            
        except Exception as e:
            print(f"   âŒ System Health API test failed: {str(e)}")
            self.test_results["System Health APIs"] = {"status": "failed", "error": str(e)}
            return False
    
    async def test_integration_scenarios(self) -> bool:
        """Test integration scenarios"""
        print("\nğŸ”— Testing Integration Scenarios...")
        
        try:
            # Scenario 1: Complete ML workflow simulation
            print("   ğŸ¯ Scenario 1: ML Workflow Integration...")
            
            # Test data flow from price data to prediction
            from app.core.database import SessionLocal
            from app.repositories import cryptocurrency_repository, price_data_repository
            
            db = SessionLocal()
            
            try:
                # Check if we have enough data for ML
                crypto = cryptocurrency_repository.get_by_symbol(db, TEST_CONFIG["crypto_symbol"])
                if crypto:
                    price_count = price_data_repository.count_by_crypto(db, crypto.id)
                    print(f"      ğŸ“Š Available price data points: {price_count}")
                    
                    if price_count >= 100:  # Minimum for ML
                        print("      âœ… Sufficient data for ML operations")
                    else:
                        print("      âš ï¸ Insufficient data for ML operations")
                
                # Test ML service integration
                from app.ml.training.training_service import training_service
                from app.ml.prediction.prediction_service import prediction_service
                
                if training_service and prediction_service:
                    print("      âœ… ML services integrated")
                else:
                    print("      âŒ ML services not integrated")
                    return False
                    
            finally:
                db.close()
            
            # Scenario 2: API endpoint integration
            print("   ğŸŒ Scenario 2: API Endpoint Integration...")
            
            # Test that all API modules are importable together
            try:
                from app.api.api_v1.endpoints import (
                    ml_training, prediction, tasks, auth, crypto, prices, health
                )
                print("      âœ… All API endpoints importable")
            except Exception as e:
                print(f"      âŒ API endpoint integration failed: {str(e)}")
                return False
            
            # Scenario 3: Schema validation integration
            print("   ğŸ“ Scenario 3: Schema Validation Integration...")
            
            try:
                from app.schemas.ml_training import TrainingRequest
                from app.schemas.prediction import PredictionRequest
                
                # Test schema creation
                training_request = TrainingRequest(
                    crypto_symbol=TEST_CONFIG["crypto_symbol"],
                    model_type="lstm"
                )
                
                prediction_request = PredictionRequest(
                    crypto_symbol=TEST_CONFIG["crypto_symbol"]
                )
                
                print("      âœ… Schema validation working")
                
            except Exception as e:
                print(f"      âŒ Schema validation failed: {str(e)}")
                return False
            
            # Scenario 4: Background task integration
            print("   âš™ï¸ Scenario 4: Background Task Integration...")
            
            try:
                from app.tasks.ml_tasks import get_task_status
                from app.tasks.price_collector import get_task_status as get_price_task_status
                
                # Test task status functions
                dummy_task_id = "test_task_123"
                ml_status = get_task_status(dummy_task_id)
                price_status = get_price_task_status(dummy_task_id)
                
                if ml_status and price_status:
                    print("      âœ… Task integration working")
                else:
                    print("      âŒ Task integration failed")
                    return False
                    
            except Exception as e:
                print(f"      âŒ Background task integration failed: {str(e)}")
                return False
            
            self.test_results["Integration Tests"] = {"status": "passed"}
            return True
            
        except Exception as e:
            print(f"   âŒ Integration test failed: {str(e)}")
            self.test_results["Integration Tests"] = {"status": "failed", "error": str(e)}
            return False
    
    def print_final_results(self, passed_categories: int, total_categories: int):
        """Print comprehensive final test results"""
        print(f"\n{'='*60}")
        print("ğŸ COMPREHENSIVE TEST RESULTS")
        print(f"{'='*60}")
        
        success_rate = (passed_categories / total_categories) * 100
        
        print(f"ğŸ“Š Overall Success Rate: {success_rate:.1f}% ({passed_categories}/{total_categories})")
        print(f"â° Test Completed: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        print(f"\nğŸ“‹ Detailed Results:")
        for category, result in self.test_results.items():
            status = result.get("status", "unknown")
            if status == "passed":
                print(f"   âœ… {category}")
            elif status == "failed":
                print(f"   âŒ {category}: {result.get('error', 'Unknown error')}")
            elif status == "error":
                print(f"   ğŸ’¥ {category}: {result.get('error', 'Unknown error')}")
            else:
                print(f"   â“ {category}: Unknown status")
        
        # Overall assessment
        print(f"\nğŸ¯ Assessment:")
        if success_rate >= 90:
            print("   ğŸ‰ EXCELLENT: System is ready for production!")
            print("   âœ¨ All major components are working correctly")
        elif success_rate >= 80:
            print("   âœ… GOOD: System is mostly ready")
            print("   ğŸ”§ Minor issues may need attention")
        elif success_rate >= 70:
            print("   âš ï¸ FAIR: System has some issues")
            print("   ğŸ› ï¸ Several components need fixing")
        else:
            print("   âŒ POOR: System needs significant work")
            print("   ğŸš¨ Multiple critical issues found")
        
        # Recommendations
        print(f"\nğŸ’¡ Recommendations:")
        if success_rate < 100:
            failed_tests = [name for name, result in self.test_results.items() 
                          if result.get("status") != "passed"]
            print(f"   ğŸ”§ Fix failed components: {', '.join(failed_tests)}")
        
        print("   ğŸ“š Review logs for detailed error information")
        print("   ğŸ”„ Run tests again after fixes")
        print("   ğŸš€ Consider load testing if all tests pass")
        
        # Next steps based on Phase 1 completion
        if success_rate >= 80:
            print(f"\nğŸš€ Phase 1 Status: READY FOR COMPLETION")
            print("   âœ… Core infrastructure working")
            print("   âœ… ML training pipeline functional")  
            print("   âœ… Prediction APIs operational")
            print("   âœ… Background tasks configured")
            print("   ğŸ¯ Ready to move to Phase 2: Enhanced Features")
        else:
            print(f"\nâš ï¸ Phase 1 Status: NEEDS MORE WORK")
            print("   ğŸ”§ Address failed tests before Phase 2")
            print("   ğŸ“Š Ensure all core functionality works")
            print("   ğŸ§ª Re-run tests after fixes")


async def main():
    """Main test function"""
    try:
        print("ğŸ”§ Initializing test environment...")
        
        # Check basic requirements
        test_requirements = [
            ("Python path", sys.path),
            ("Backend directory", os.path.exists("backend")),
            ("Current directory", os.getcwd())
        ]
        
        for req_name, req_check in test_requirements:
            if req_check:
                print(f"   âœ… {req_name}: OK")
            else:
                print(f"   âŒ {req_name}: FAILED")
                return
        
        print("\nğŸ§ª Starting comprehensive test suite...")
        
        # Create and run test suite
        test_suite = APITestSuite()
        await test_suite.run_all_tests()
        
        print(f"\nğŸ Test suite completed!")
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Test suite interrupted by user")
    except Exception as e:
        print(f"\nğŸ’¥ Test suite failed: {str(e)}")
        traceback.print_exc()


if __name__ == "__main__":
    # Check if we're in the right directory
    if not os.path.exists("backend"):
        print("âŒ Please run this script from the project root directory")
        print("ğŸ“ Current directory:", os.getcwd())
        sys.exit(1)
    
    # Run the test suite
    asyncio.run(main())