# File: backend/app/ml/prediction/prediction_service.py
# Real-time Prediction Service for CryptoPredict

import asyncio
import logging
import json
import time
from typing import Dict, Any, Optional, List, Tuple
from datetime import datetime, timedelta, timezone
from decimal import Decimal
import pandas as pd
import numpy as np
from sqlalchemy.orm import Session

# Redis for caching
try:
    import redis
    from redis import Redis
except ImportError:
    redis = None

# Import existing ML components
from app.ml.models.lstm_predictor import LSTMPredictor
from app.ml.preprocessing.data_processor import CryptoPriceDataProcessor
from app.ml.config.ml_config import ml_config, model_registry
from app.ml.utils.model_utils import ModelMetrics

# Import existing database components
from app.core.database import SessionLocal
from app.core.config import settings
from app.repositories import (
    cryptocurrency_repository, 
    price_data_repository,
    prediction_repository
)
from app.repositories.ml_repository import ml_repository
from app.models import Cryptocurrency, PriceData, Prediction
from app.schemas.prediction import PredictionCreate

logger = logging.getLogger(__name__)


class PredictionService:
    """
    Real-time Prediction Service for Cryptocurrency Price Prediction
    
    Features:
    - Real-time predictions for multiple cryptocurrencies
    - Model loading and caching
    - Confidence interval calculation
    - Performance monitoring
    - Redis caching for fast responses
    - Automatic fallback mechanisms
    """
    
    def __init__(self):
        """Initialize prediction service"""
        self.data_processor = CryptoPriceDataProcessor(
            scaling_method=ml_config.scaling_method,
            handle_missing=ml_config.handle_missing,
            add_technical_indicators=ml_config.add_technical_indicators,
            add_time_features=ml_config.add_time_features,
            add_price_features=ml_config.add_price_features,
            outlier_threshold=ml_config.outlier_threshold,
            min_data_points=ml_config.min_data_points
        )
        
        # Model cache for loaded models
        self.model_cache = {}
        self.model_cache_timestamps = {}
        self.cache_ttl = 3600  # 1 hour
        
        # Redis cache for predictions
        self.redis_client = None
        if redis and hasattr(settings, 'REDIS_URL'):
            try:
                self.redis_client = redis.from_url(settings.REDIS_URL)
                # Test connection
                self.redis_client.ping()
                logger.info("Redis connection established for prediction caching")
            except Exception as e:
                logger.warning(f"Redis connection failed: {e}")
                self.redis_client = None
        
        # Performance tracking
        self.performance_metrics = {
            'total_predictions': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'average_response_time': 0.0,
            'error_count': 0
        }
        
        logger.info("PredictionService initialized successfully")
    
    async def predict_price(
        self,
        crypto_symbol: str,
        prediction_horizon: int = 24,  # hours
        use_cache: bool = True,
        db: Optional[Session] = None
    ) -> Dict[str, Any]:
        """
        Generate price prediction for a cryptocurrency
        
        Args:
            crypto_symbol: Symbol of cryptocurrency (e.g., 'BTC')
            prediction_horizon: Hours ahead to predict (default: 24)
            use_cache: Whether to use cached predictions
            db: Database session
            
        Returns:
            Dictionary with prediction results
        """
        start_time = time.time()
        close_db = False
        
        try:
            # Database session management
            if db is None:
                db = SessionLocal()
                close_db = True
            
            # Step 1: Check cache first
            if use_cache and self.redis_client:
                cached_result = await self._get_cached_prediction(
                    crypto_symbol, prediction_horizon
                )
                if cached_result:
                    self.performance_metrics['cache_hits'] += 1
                    self._update_response_time(time.time() - start_time)
                    return cached_result
                
                self.performance_metrics['cache_misses'] += 1
            
            # Step 2: Validate cryptocurrency
            crypto = cryptocurrency_repository.get_by_symbol(db, crypto_symbol)
            if not crypto:
                raise ValueError(f"Cryptocurrency {crypto_symbol} not found")
            
            if not crypto.is_active:
                raise ValueError(f"Cryptocurrency {crypto_symbol} is not active")
            
            # Step 3: Load or get cached model
            model = await self._load_model(crypto_symbol)
            if not model:
                raise ValueError(f"No trained model available for {crypto_symbol}")
            
            # ðŸ” DEBUG: Model Configuration
            logger.info("=" * 60)
            logger.info("ðŸ” MODEL CONFIGURATION DEBUG")
            logger.info("=" * 60)
            logger.info(f"Model name: {getattr(model, 'model_name', 'Unknown')}")
            logger.info(f"Model n_features: {getattr(model, 'n_features', 'Not set')}")
            logger.info(f"Model sequence_length: {getattr(model, 'sequence_length', 'Not set')}")
            logger.info(f"Model is_trained: {getattr(model, 'is_trained', 'Unknown')}")
            logger.info(f"Model type: {type(model)}")
            
        
            # Check if model has keras model loaded
            if hasattr(model, 'model') and model.model:
                try:
                    input_shape = model.model.input_shape
                    logger.info(f"Keras model input_shape: {input_shape}")
                    logger.info(f"Expected format: (batch_size, sequence_length, n_features)")
                    if len(input_shape) == 3:
                        logger.info(f"  - Batch size: {input_shape[0]} (None expected)")
                        logger.info(f"  - Sequence length: {input_shape[1]}")
                        logger.info(f"  - Features: {input_shape[2]}")
                except Exception as e:
                    logger.warning(f"Could not get keras model input shape: {e}")

            # Step 4: Prepare input data
            logger.info("=" * 60)
            logger.info("ðŸ” INPUT DATA PREPARATION DEBUG")
            logger.info("=" * 60)
            
            model_sequence_length = 30
            logger.info(f"Using sequence_length: {model_sequence_length}")
            
            input_data = await self._prepare_prediction_input(
                db, crypto.id, model_sequence_length
            )
            
            if input_data is None:
                raise ValueError("Failed to prepare input data")
            
            # ðŸ” DEBUG: Input Data Shape
            logger.info(f"Input data shape: {input_data.shape}")
            logger.info(f"Input data type: {type(input_data)}")
            logger.info(f"Input data dtype: {input_data.dtype}")
            logger.info(f"Input data min: {input_data.min():.6f}")
            logger.info(f"Input data max: {input_data.max():.6f}")
            logger.info(f"Input data mean: {input_data.mean():.6f}")
            
            # Show sample of input data
            logger.info("Sample input data (first 3 timesteps):")
            for i in range(min(3, input_data.shape[1])):
                logger.info(f"  Timestep {i}: {input_data[0, i, :].tolist()}")
            
            logger.info("ðŸš€ Data prepared, proceeding with prediction...")
            
            # Step 5: Generate prediction
            logger.info("=" * 60)
            logger.info("ðŸ” ATTEMPTING MODEL PREDICTION")
            logger.info("=" * 60)
            
            try:
                # Make prediction with detailed error catching
                prediction_result = await self._generate_prediction(
                    model, input_data, prediction_horizon
                )
                
                logger.info(f"âœ… Prediction successful: {prediction_result}")
                
            except Exception as pred_error:
                logger.error(f"âŒ PREDICTION FAILED: {str(pred_error)}")
                logger.error(f"Error type: {type(pred_error)}")
                
                # Import traceback for detailed error info
                import traceback
                logger.error("Full error traceback:")
                logger.error(traceback.format_exc())
                
                # Provide specific solutions based on error
                error_str = str(pred_error).lower()
                if "dimensions must be equal" in error_str:
                    logger.error("ðŸ”§ SOLUTION: This is a feature count mismatch")
                    logger.error("   - Either retrain model with current feature count")
                    logger.error("   - Or modify data preparation to match model features")
                
                if "input shape" in error_str:
                    logger.error("ðŸ”§ SOLUTION: This is an input shape mismatch")
                    logger.error("   - Check sequence_length parameter")
                    logger.error("   - Verify data preprocessing pipeline")
                
                raise pred_error
            
            # Step 6: Calculate confidence intervals
            confidence_data = await self._calculate_confidence(
                model, input_data, prediction_result
            )
            
            # Step 7: Get current price for comparison
            current_price = await self._get_current_price(db, crypto.id)
            
            # Step 8: Prepare result
            result = {
                'success': True,
                'crypto_symbol': crypto_symbol,
                'current_price': float(current_price),
                'predicted_price': float(prediction_result['price']),
                'prediction_horizon_hours': prediction_horizon,
                'confidence_score': float(confidence_data['confidence']),
                'confidence_interval': {
                    'lower': float(confidence_data['lower_bound']),
                    'upper': float(confidence_data['upper_bound'])
                },
                'model_info': {
                    'model_id': model.model_name,
                    'features_used': input_data.shape[1] if len(input_data.shape) > 1 else 1,
                    'sequence_length': model.sequence_length,
                    'last_training': self._get_model_training_date(crypto_symbol)
                },
                'prediction_metadata': {
                    'timestamp': datetime.utcnow().isoformat(),
                    'response_time_ms': round((time.time() - start_time) * 1000, 2),
                    'cache_used': False,
                    'data_points_used': len(input_data)
                }
            }
            
            # Step 9: Cache result
            if self.redis_client:
                await self._cache_prediction(crypto_symbol, prediction_horizon, result)
            
            # Step 10: Store prediction in database
            await self._store_prediction_result(db, crypto.id, result)
            
            # Update performance metrics
            self.performance_metrics['total_predictions'] += 1
            self._update_response_time(time.time() - start_time)
            
            logger.info(f"Prediction generated for {crypto_symbol}: "
                       f"${result['predicted_price']:.2f} "
                       f"(confidence: {result['confidence_score']:.2f})")
            
            return result
            
        except Exception as e:
            self.performance_metrics['error_count'] += 1
            logger.error(f"Prediction failed for {crypto_symbol}: {str(e)}")
            
            # Try fallback prediction
            fallback_result = await self._fallback_prediction(db, crypto_symbol, prediction_horizon)
            
            if fallback_result:
                fallback_result['prediction_metadata']['fallback_used'] = True
                return fallback_result
            
            return {
                'success': False,
                'crypto_symbol': crypto_symbol,
                'error': str(e),
                'prediction_horizon_hours': prediction_horizon,
                'timestamp': datetime.utcnow().isoformat(),
                'response_time_ms': round((time.time() - start_time) * 1000, 2)
            }
            
        finally:
            if close_db:
                db.close()
    
    async def predict_batch(
        self,
        crypto_symbols: List[str],
        prediction_horizon: int = 24,
        max_concurrent: int = 5
    ) -> Dict[str, Any]:
        """
        Generate predictions for multiple cryptocurrencies
        
        Args:
            crypto_symbols: List of cryptocurrency symbols
            prediction_horizon: Hours ahead to predict
            max_concurrent: Maximum concurrent predictions
            
        Returns:
            Dictionary with results for each symbol
        """
        semaphore = asyncio.Semaphore(max_concurrent)
        
        async def predict_single(symbol: str) -> Tuple[str, Dict[str, Any]]:
            async with semaphore:
                result = await self.predict_price(symbol, prediction_horizon)
                return symbol, result
        
        # Execute batch predictions
        tasks = [predict_single(symbol) for symbol in crypto_symbols]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Process results
        batch_result = {
            'success': True,
            'predictions': {},
            'summary': {
                'total_requested': len(crypto_symbols),
                'successful': 0,
                'failed': 0,
                'timestamp': datetime.utcnow().isoformat()
            }
        }
        
        for result in results:
            if isinstance(result, Exception):
                batch_result['summary']['failed'] += 1
                continue
                
            symbol, prediction = result
            batch_result['predictions'][symbol] = prediction
            
            if prediction.get('success', False):
                batch_result['summary']['successful'] += 1
            else:
                batch_result['summary']['failed'] += 1
        
        return batch_result
    
    async def _load_model(self, crypto_symbol: str) -> Optional[LSTMPredictor]:
        """Load model for cryptocurrency (with caching)"""
        
        # Check cache first
        cache_key = f"model_{crypto_symbol}"
        
        if cache_key in self.model_cache:
            # Check if cache is still valid
            cache_time = self.model_cache_timestamps.get(cache_key, 0)
            if time.time() - cache_time < self.cache_ttl:
                return self.model_cache[cache_key]
            else:
                # Remove expired cache
                del self.model_cache[cache_key]
                del self.model_cache_timestamps[cache_key]
        
        # Load model from registry
        try:
            active_model = model_registry.get_active_model(crypto_symbol)
            if not active_model:
                logger.warning(f"No active model found for {crypto_symbol}")
                return None
            
            model_path = active_model.get('model_path')
            if not model_path:
                logger.warning(f"No model path for {crypto_symbol}")
                return None
            
            # Create and load LSTM predictor
            model = LSTMPredictor()
            model.load_model(model_path)
            
            # Cache the loaded model
            self.model_cache[cache_key] = model
            self.model_cache_timestamps[cache_key] = time.time()
            
            logger.info(f"Model loaded for {crypto_symbol}: {model_path}")
            return model
            
        except Exception as e:
            logger.error(f"Failed to load model for {crypto_symbol}: {str(e)}")
            return None
    
    async def _prepare_prediction_input(
        self, 
        db: Session, 
        crypto_id: int, 
        sequence_length: int
    ) -> np.ndarray:
        """Prepare input data for prediction - FIXED VERSION"""
        
        logger.info(f"Preparing input data with sequence_length: {sequence_length}")
        
        # Get recent price data as numpy array
        recent_data = ml_repository.get_recent_data_for_prediction(
            db=db,
            crypto_id=crypto_id,
            sequence_length=sequence_length  # This should be 30
        )
        
        # Check if data is valid
        if recent_data is None or recent_data.size == 0:
            raise ValueError("Insufficient recent data for prediction")
        
        # REMOVE: Skip data_processor completely (causes the columns error)
        # The data is already processed in ml_repository
        
        logger.info(f"Prepared prediction input with shape: {recent_data.shape}")
        return recent_data  

    async def _generate_prediction(
        self,
        model: LSTMPredictor,
        input_data: np.ndarray,
        prediction_horizon: int
    ) -> Dict[str, Any]:
        """Generate prediction with detailed debugging"""
        
        logger.info("ðŸŽ¯ Starting model prediction generation...")
        logger.info(f"Input shape for model: {input_data.shape}")
        
        try:
            # ðŸ” Pre-prediction validation
            logger.info("Validating input data before prediction...")
            
            # Check for NaN or infinite values
            if np.any(np.isnan(input_data)):
                logger.warning("âš ï¸ Found NaN values in input data")
                
            if np.any(np.isinf(input_data)):
                logger.warning("âš ï¸ Found infinite values in input data")
                
            # Log model method being called
            logger.info(f"Calling model.predict() with return_confidence=True")
            
            # Generate prediction
            predicted_price, confidence = model.predict(
                input_data, 
                return_confidence=True
            )
            
            logger.info(f"âœ… Raw prediction result: {predicted_price}")
            logger.info(f"âœ… Raw confidence: {confidence}")
            
            # Handle prediction results...
            return {
                'price': predicted_price[0] if isinstance(predicted_price, np.ndarray) else predicted_price,
                'raw_confidence': confidence,
                'horizon_hours': prediction_horizon
            }
            
        except Exception as e:
            logger.error(f"âŒ Model prediction failed: {str(e)}")
            logger.error(f"Error type: {type(e)}")
            raise ValueError(f"Prediction generation failed: {str(e)}")
 
    async def _calculate_confidence(
        self,
        model: LSTMPredictor,
        input_data: np.ndarray,
        prediction_result: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Calculate confidence intervals for prediction - FIXED"""
        
        try:
            predicted_price = prediction_result['price']
            raw_confidence = prediction_result.get('raw_confidence')
            
            # Handle numpy array confidence
            if isinstance(raw_confidence, np.ndarray):
                if raw_confidence.size > 0:
                    # Take mean of confidence values
                    base_confidence = float(np.mean(raw_confidence))
                else:
                    base_confidence = 0.75
            else:
                base_confidence = float(raw_confidence) if raw_confidence else 0.75
            
            # Normalize to 0-1 range
            if base_confidence > 100:
                base_confidence = base_confidence / 100000  # Very large numbers
            elif base_confidence > 1:
                base_confidence = base_confidence / 100
            
            base_confidence = max(0.0, min(base_confidence, 0.95))  # Clamp 0-95%
            
            # Calculate confidence interval
            confidence_range = abs(predicted_price) * 0.05
            
            return {
                'confidence': base_confidence * 100,  # Convert to percentage
                'lower_bound': predicted_price - confidence_range,
                'upper_bound': predicted_price + confidence_range,
                'interval_width': confidence_range * 2
            }
            
        except Exception as e:
            logger.warning(f"Confidence calculation failed: {str(e)}")
            return {
                'confidence': 75.0,
                'lower_bound': predicted_price * 0.95,
                'upper_bound': predicted_price * 1.05,
                'interval_width': predicted_price * 0.1
            }

    async def _fallback_prediction(
        self,
        db: Session,
        crypto_symbol: str,
        prediction_horizon: int
    ) -> Dict[str, Any]:
        """Generate fallback prediction when ML fails - FIXED"""
        
        try:
            logger.info(f"Generating fallback prediction for {crypto_symbol}")
            
            # Get current price from database or use defaults
            fallback_prices = {
                "BTC": 47000.0,  # Use float instead of Decimal
                "ETH": 3000.0,
                "ADA": 0.45,
                "DOT": 8.0
            }
            
            current_price = fallback_prices.get(crypto_symbol.upper(), 1000.0)
            
            # Simple prediction: slight increase based on historical trend
            growth_factor = 1.02  # 2% growth
            predicted_price = current_price * growth_factor
            
            return {
                'success': True,
                'crypto_symbol': crypto_symbol,
                'current_price': current_price,
                'predicted_price': predicted_price,
                'prediction_horizon_hours': prediction_horizon,
                'confidence_score': 50.0,  # Low confidence for fallback
                'model_info': {
                    'model_id': 'fallback_model',
                    'features_used': ['price_trend'],
                    'last_training': None
                },
                'prediction_metadata': {
                    'timestamp': datetime.now(timezone.utc).isoformat(),
                    'cache_used': False,
                    'is_fallback': True
                }
            }
            
        except Exception as e:
            logger.error(f"Fallback prediction failed: {str(e)}")
            return {
                'success': False,
                'error': f"Fallback prediction failed: {str(e)}"
            }
            
    async def _get_current_price(self, db: Session, crypto_id: int) -> float:
        """Get current market price as float"""
        
        try:
            # Try to get from database
            from app.repositories import price_data_repository
            
            latest_price = price_data_repository.get_latest_price(db, crypto_id)
            
            if latest_price and latest_price.close_price:
                return float(latest_price.close_price)  # Convert Decimal to float
            
            # Fallback prices by crypto_id
            fallback_prices = {
                1: 47000.0,  # BTC
                2: 3000.0,   # ETH  
                3: 0.45,     # ADA
                4: 8.0       # DOT
            }
            
            return fallback_prices.get(crypto_id, 1000.0)
            
        except Exception as e:
            logger.warning(f"Failed to get current price for crypto_id {crypto_id}: {e}")
            return 47000.0  # Safe fallback
        
    def _get_model_training_date(self, crypto_symbol: str) -> Optional[str]:
        """Get model training date from registry"""
        try:
            active_model = model_registry.get_active_model(crypto_symbol)
            if active_model and 'metadata' in active_model:
                return active_model['metadata'].get('registered_at')
            return None
        except Exception:
            return None
            
    async def _cache_prediction(
        self,
        crypto_symbol: str,
        prediction_horizon: int,
        result: Dict[str, Any]
    ) -> None:
        """Cache prediction result - FIXED for sync Redis"""
        
        try:
            # Use simple in-memory cache (most reliable)
            if not hasattr(self, '_memory_cache'):
                self._memory_cache = {}
            
            cache_key = f"{crypto_symbol}_{prediction_horizon}h"
            cache_data = {
                'result': result,
                'cached_at': datetime.now(timezone.utc),
                'expires_at': datetime.now(timezone.utc) + timedelta(minutes=30)
            }
            
            self._memory_cache[cache_key] = cache_data
            logger.info(f"Prediction cached in memory for {crypto_symbol}")
            
            # Optional: Try Redis sync if available
            if self.redis_client and hasattr(self.redis_client, 'setex'):
                try:
                    # Use SYNC Redis operations (no await)
                    cache_json = json.dumps({
                        'crypto_symbol': crypto_symbol,
                        'predicted_price': float(result.get('predicted_price', 0)),
                        'current_price': float(result.get('current_price', 0)),
                        'confidence_score': float(result.get('confidence_score', 0)),
                        'cached_at': datetime.now(timezone.utc).isoformat()
                    })
                    
                    self.redis_client.setex(f"prediction:{cache_key}", 1800, cache_json)  # 30 min
                    logger.info(f"Prediction also cached in Redis for {crypto_symbol}")
                    
                except Exception as redis_e:
                    logger.warning(f"Redis cache failed, using memory cache: {redis_e}")
            
        except Exception as e:
            logger.warning(f"Failed to cache prediction: {str(e)}")
            # Continue without caching

    async def _store_prediction_result(
        self, 
        db: Session, 
        crypto_id: int, 
        result: Dict[str, Any]
    ) -> None:
        """Store prediction result in database - FIXED"""
        
        try:
            # Import here to avoid circular imports
            from app.models.prediction import Prediction
            
            # Calculate target datetime
            prediction_horizon = result.get('prediction_horizon_hours', 24)
            target_datetime = datetime.now(timezone.utc) + timedelta(hours=prediction_horizon)
            
            # Get model info
            model_info = result.get('model_info', {})
            model_name = model_info.get('model_id', 'LSTM_Model')
            
            # Create prediction record
            prediction = Prediction(
                crypto_id=crypto_id,
                model_name=model_name,
                model_version='1.0',
                predicted_price=float(result.get('predicted_price', 0.0)),
                confidence_score=float(result.get('confidence_score', 75.0)),
                prediction_horizon=prediction_horizon,
                target_datetime=target_datetime,
                input_price=float(result.get('current_price', 0.0)) if result.get('current_price') else None,
                is_realized=False,
                accuracy_threshold=5.0,
                notes=f"Generated by {model_name} model"
            )
            
            db.add(prediction)
            db.commit()
            
            logger.info(f"Prediction stored in database: ID={prediction.id}, Price=${prediction.predicted_price}")
            
        except Exception as e:
            logger.warning(f"Failed to store prediction in database: {str(e)}")
            # Don't fail the whole prediction if database storage fails
            db.rollback()

            
# Global prediction service instance
prediction_service = PredictionService()


# Helper functions for easy access
async def predict_crypto_price(
    crypto_symbol: str,
    prediction_horizon: int = 24,
    use_cache: bool = True
) -> Dict[str, Any]:
    """
    Simple helper function for single cryptocurrency prediction
    
    Args:
        crypto_symbol: Symbol of cryptocurrency (e.g., 'BTC')
        prediction_horizon: Hours ahead to predict (default: 24)
        use_cache: Whether to use cached predictions
        
    Returns:
        Prediction result dictionary
    """
    return await prediction_service.predict_price(
        crypto_symbol=crypto_symbol,
        prediction_horizon=prediction_horizon,
        use_cache=use_cache
    )


async def predict_multiple_cryptos(
    crypto_symbols: List[str],
    prediction_horizon: int = 24
) -> Dict[str, Any]:
    """
    Simple helper function for multiple cryptocurrency predictions
    
    Args:
        crypto_symbols: List of cryptocurrency symbols
        prediction_horizon: Hours ahead to predict
        
    Returns:
        Batch prediction results
    """
    return await prediction_service.predict_batch(
        crypto_symbols=crypto_symbols,
        prediction_horizon=prediction_horizon
    )


async def get_prediction_performance() -> Dict[str, Any]:
    """Get prediction service performance metrics"""
    return prediction_service.get_performance_metrics()


async def clear_prediction_cache() -> Dict[str, Any]:
    """Clear all prediction caches"""
    return prediction_service.clear_cache()