# backend/app/api/api_v1/endpoints/tasks.py
"""
Task Management API Endpoints - FINAL VERSION
Provides REST API for managing background tasks and monitoring
Complete and tested implementation for CryptoPredict MVP
"""

from fastapi import APIRouter, HTTPException, Depends, BackgroundTasks
from typing import Dict, Any, Optional
import logging
from datetime import datetime, timezone
import asyncio

from app.core.deps import get_current_active_user
from app.models.user import User
from app.tasks.price_collector import (
    sync_all_prices,
    sync_historical_data,
    discover_new_cryptocurrencies,
    cleanup_old_data,
    sync_specific_cryptocurrency,
    get_task_status
)
from app.tasks.scheduler import task_scheduler, get_next_run_times
from app.tasks.celery_app import celery_app

# Setup logging
logger = logging.getLogger(__name__)

# Create router
router = APIRouter()


@router.post("/start", response_model=Dict[str, Any])
async def start_background_tasks(
    current_user: User = Depends(get_current_active_user)
) -> Dict[str, Any]:
    """
    Start all background tasks manually
    
    Requires authentication. Starts immediate execution of all main background tasks:
    - Price synchronization for all active cryptocurrencies
    - Historical data sync for recent periods  
    - New cryptocurrency discovery
    
    Returns:
        dict: Task start results with task IDs and status
    """
    try:
        logger.info(f"User {current_user.email} starting background tasks")
        
        # Start immediate execution of all main tasks
        price_task = sync_all_prices.delay()
        historical_task = sync_historical_data.delay(days=7)
        discovery_task = discover_new_cryptocurrencies.delay(limit=50)
        
        return {
            "status": "success",
            "message": "Background tasks started successfully",
            "tasks": {
                "price_sync": {
                    "task_id": price_task.id,
                    "status": "started",
                    "description": "Synchronizing current prices for all active cryptocurrencies"
                },
                "historical_sync": {
                    "task_id": historical_task.id, 
                    "status": "started",
                    "description": "Synchronizing historical data for the last 7 days"
                },
                "crypto_discovery": {
                    "task_id": discovery_task.id,
                    "status": "started", 
                    "description": "Discovering new cryptocurrencies (limit: 50)"
                }
            },
            "started_by": current_user.email,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to start background tasks: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to start tasks: {str(e)}")


@router.post("/stop", response_model=Dict[str, Any])
async def stop_background_tasks(
    current_user: User = Depends(get_current_active_user)
) -> Dict[str, Any]:
    """
    Stop all active background tasks
    
    Requires authentication. Terminates all currently running background tasks.
    Use with caution as this will interrupt ongoing data synchronization.
    
    Returns:
        dict: Task stop results with list of stopped tasks
    """
    try:
        logger.info(f"User {current_user.email} stopping background tasks")
        
        # Get active tasks
        inspect = celery_app.control.inspect()
        active_tasks = inspect.active()
        
        stopped_tasks = []
        if active_tasks:
            for worker, tasks in active_tasks.items():
                for task in tasks:
                    task_id = task['id']
                    task_name = task['name']
                    
                    # Revoke the task
                    celery_app.control.revoke(task_id, terminate=True)
                    stopped_tasks.append({
                        "task_id": task_id,
                        "task_name": task_name,
                        "worker": worker
                    })
        
        return {
            "status": "success",
            "message": f"Stopped {len(stopped_tasks)} active tasks",
            "stopped_tasks": stopped_tasks,
            "stopped_by": current_user.email,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to stop background tasks: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to stop tasks: {str(e)}")


@router.get("/status", response_model=Dict[str, Any])
async def get_tasks_status() -> Dict[str, Any]:
    """
    Get comprehensive status of all background tasks
    
    No authentication required for status monitoring.
    Provides detailed information about task system health, active tasks,
    scheduling information, and worker statistics.
    
    Returns:
        dict: Comprehensive task status information
    """
    try:
        # Get basic task status
        basic_status = get_task_status.delay().get(timeout=10)
        
        # Get schedule information
        schedule_info = task_scheduler.get_schedule_info()
        
        # Get active tasks
        active_tasks = task_scheduler.get_active_tasks()
        
        # Get worker stats
        worker_stats = task_scheduler.get_worker_stats()
        
        # Get next run times
        next_runs = get_next_run_times()
        
        return {
            "status": "success",
            "basic_status": basic_status,
            "schedule_info": schedule_info,
            "active_tasks": active_tasks,
            "worker_stats": worker_stats,
            "next_run_times": next_runs,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to get task status: {e}")
        return {
            "status": "error",
            "error": str(e),
            "message": "Unable to retrieve task status. Check if Celery workers are running.",
            "timestamp": datetime.now(timezone.utc).isoformat()
        }


@router.post("/manual/{task_name}", response_model=Dict[str, Any])
async def run_manual_task(
    task_name: str,
    days: Optional[int] = None,
    crypto_symbol: Optional[str] = None,
    current_user: User = Depends(get_current_active_user)
) -> Dict[str, Any]:
    """
    Run a specific task manually with custom parameters
    
    Requires authentication. Available tasks:
    - sync_prices: Sync current prices for all cryptocurrencies
    - sync_historical: Sync historical data (specify days parameter)
    - discover_cryptos: Discover new cryptocurrencies
    - cleanup_data: Clean up old data
    - sync_specific: Sync specific cryptocurrency (specify crypto_symbol)
    
    Args:
        task_name: Name of task to run
        days: Optional days parameter for historical sync (default: 30)
        crypto_symbol: Optional crypto symbol for specific sync (e.g., 'BTC')
        
    Returns:
        dict: Task execution result with task ID and parameters
    """
    try:
        logger.info(f"User {current_user.email} running manual task: {task_name}")
        
        # Map task names to functions and descriptions
        task_map = {
            "sync_prices": {
                "func": sync_all_prices,
                "description": "Sync current prices for all cryptocurrencies"
            },
            "sync_historical": {
                "func": sync_historical_data,
                "description": "Sync historical data for cryptocurrencies"
            },
            "discover_cryptos": {
                "func": discover_new_cryptocurrencies,
                "description": "Discover and add new cryptocurrencies"
            },
            "cleanup_data": {
                "func": cleanup_old_data,
                "description": "Clean up old price data to manage storage"
            },
            "sync_specific": {
                "func": sync_specific_cryptocurrency,
                "description": "Sync data for a specific cryptocurrency"
            }
        }
        
        if task_name not in task_map:
            raise HTTPException(
                status_code=400, 
                detail=f"Unknown task: {task_name}. Available tasks: {list(task_map.keys())}"
            )
        
        task_info = task_map[task_name]
        task_func = task_info["func"]
        
        # Execute task with appropriate parameters
        if task_name == "sync_historical":
            days = days or 30
            result_task = task_func.delay(days=days)
            parameters = {"days": days}
        elif task_name == "sync_specific":
            if not crypto_symbol:
                raise HTTPException(
                    status_code=400,
                    detail="crypto_symbol parameter is required for sync_specific task"
                )
            result_task = task_func.delay(crypto_symbol=crypto_symbol.upper())
            parameters = {"crypto_symbol": crypto_symbol.upper()}
        elif task_name == "discover_cryptos":
            result_task = task_func.delay(limit=100)
            parameters = {"limit": 100}
        elif task_name == "cleanup_data":
            result_task = task_func.delay(days_to_keep=365)
            parameters = {"days_to_keep": 365}
        else:
            result_task = task_func.delay()
            parameters = {}
        
        return {
            "status": "success",
            "message": f"Task '{task_name}' started manually",
            "task_id": result_task.id,
            "task_name": task_name,
            "description": task_info["description"],
            "parameters": parameters,
            "started_by": current_user.email,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to run manual task {task_name}: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to run task: {str(e)}")


@router.get("/result/{task_id}", response_model=Dict[str, Any])
async def get_task_result(
    task_id: str,
    current_user: User = Depends(get_current_active_user)
) -> Dict[str, Any]:
    """
    Get result of a specific task by ID
    
    Requires authentication. Retrieves the execution result, status,
    and metadata for a specific background task.
    
    Args:
        task_id: Unique identifier of the task
        
    Returns:
        dict: Comprehensive task result information
    """
    try:
        # Get task result from Celery
        result = celery_app.AsyncResult(task_id)
        
        # Determine task state description
        state_descriptions = {
            "PENDING": "Task is waiting to be processed",
            "STARTED": "Task has been started and is running",
            "SUCCESS": "Task completed successfully",
            "FAILURE": "Task failed to complete",
            "RETRY": "Task is being retried after failure",
            "REVOKED": "Task was cancelled/revoked"
        }
        
        return {
            "status": "success",
            "task_id": task_id,
            "task_status": result.status,
            "status_description": state_descriptions.get(result.status, "Unknown status"),
            "task_result": result.result if result.ready() else None,
            "task_info": result.info,
            "ready": result.ready(),
            "successful": result.successful() if result.ready() else None,
            "failed": result.failed() if result.ready() else None,
            "date_done": result.date_done.isoformat() if result.date_done else None,
            "traceback": result.traceback if result.failed() else None,
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to get task result for {task_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to get task result: {str(e)}")


@router.delete("/revoke/{task_id}", response_model=Dict[str, Any])
async def revoke_task(
    task_id: str,
    terminate: bool = False,
    current_user: User = Depends(get_current_active_user)
) -> Dict[str, Any]:
    """
    Revoke (cancel) a specific task
    
    Requires authentication. Cancels a running or pending task.
    Use terminate=True to forcefully kill a running task.
    
    Args:
        task_id: Unique identifier of the task to revoke
        terminate: Whether to terminate the task immediately (default: False)
        
    Returns:
        dict: Revocation result
    """
    try:
        logger.info(f"User {current_user.email} revoking task: {task_id}")
        
        # Revoke the task
        result = task_scheduler.revoke_task(task_id, terminate=terminate)
        
        result["revoked_by"] = current_user.email
        result["terminate_used"] = terminate
        return result
        
    except Exception as e:
        logger.error(f"Failed to revoke task {task_id}: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to revoke task: {str(e)}")


@router.post("/purge", response_model=Dict[str, Any])
async def purge_task_queue(
    queue_name: str = "default",
    current_user: User = Depends(get_current_active_user)
) -> Dict[str, Any]:
    """
    Purge all tasks from a specific queue
    
    Requires authentication. Removes all pending tasks from the specified queue.
    Use with extreme caution as this will cancel all waiting tasks.
    
    Args:
        queue_name: Name of queue to purge (default: "default")
        
    Returns:
        dict: Purge operation result
    """
    try:
        logger.warning(f"User {current_user.email} purging queue: {queue_name}")
        
        # Purge the queue
        result = task_scheduler.purge_queue(queue_name)
        
        result["purged_by"] = current_user.email
        result["queue_name"] = queue_name
        return result
        
    except Exception as e:
        logger.error(f"Failed to purge queue {queue_name}: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to purge queue: {str(e)}")


@router.get("/schedules", response_model=Dict[str, Any])
async def get_task_schedules() -> Dict[str, Any]:
    """
    Get information about all scheduled tasks
    
    No authentication required. Returns information about periodic task schedules,
    next execution times, and scheduling configuration.
    
    Returns:
        dict: Comprehensive scheduling information
    """
    try:
        # Get schedule info
        schedule_info = task_scheduler.get_schedule_info()
        
        # Get next run times
        next_runs = get_next_run_times()
        
        # Add human-readable schedule descriptions
        schedule_descriptions = {
            "sync-prices-every-5-minutes": "Current price sync every 5 minutes",
            "sync-historical-every-hour": "Historical data sync every hour at minute 0",
            "discover-new-cryptos-daily": "New cryptocurrency discovery daily at 2:00 AM",
            "cleanup-old-data-weekly": "Data cleanup weekly on Sunday at 3:00 AM"
        }
        
        return {
            "status": "success",
            "schedule_info": schedule_info,
            "next_run_times": next_runs,
            "schedule_descriptions": schedule_descriptions,
            "total_scheduled_tasks": len(schedule_descriptions),
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Failed to get task schedules: {e}")
        return {
            "status": "error",
            "error": str(e),
            "timestamp": datetime.now(timezone.utc).isoformat()
        }


@router.get("/health", response_model=Dict[str, Any])
async def task_system_health() -> Dict[str, Any]:
    """
    Comprehensive health check for the task system
    
    No authentication required. Provides detailed health information about
    the background task system including worker status, broker connectivity,
    and system performance metrics.
    
    Returns:
        dict: Detailed task system health status
    """
    try:
        # Test basic task execution
        health_task = get_task_status.delay()
        health_result = health_task.get(timeout=5)
        
        # Get worker stats
        worker_stats = task_scheduler.get_worker_stats()
        
        # Test broker connectivity
        broker_status = "unknown"
        try:
            inspect = celery_app.control.inspect()
            stats = inspect.stats()
            broker_status = "connected" if stats else "disconnected"
        except Exception:
            broker_status = "disconnected"
        
        # Check Redis connectivity
        redis_status = "unknown"
        try:
            import redis
            r = redis.Redis(host='localhost', port=6379, db=0)
            r.ping()
            redis_status = "connected"
        except Exception:
            redis_status = "disconnected"
        
        return {
            "status": "healthy",
            "message": "Task system is operational",
            "components": {
                "celery_workers": worker_stats.get("status", "unknown"),
                "broker_connection": broker_status,
                "redis_connection": redis_status,
                "task_execution": "working" if health_result else "failed"
            },
            "health_check_result": health_result,
            "worker_statistics": worker_stats,
            "recommendations": [
                "Ensure Celery workers are running for task execution",
                "Monitor Redis connection for task queuing",
                "Check worker logs for any errors or warnings",
                "Verify background task schedules are executing properly"
            ],
            "timestamp": datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        logger.error(f"Task system health check failed: {e}")
        return {
            "status": "unhealthy",
            "error": str(e),
            "message": "Task system health check failed. Check Celery workers and Redis connection.",
            "troubleshooting": [
                "Start Celery workers: ./temp/start-celery.sh",
                "Check Redis is running: redis-cli ping",
                "Verify task configuration: check logs for errors",
                "Restart services if needed"
            ],
            "timestamp": datetime.now(timezone.utc).isoformat()
        }


@router.get("/info", response_model=Dict[str, Any])
async def get_task_system_info() -> Dict[str, Any]:
    """
    Get comprehensive information about the task system
    
    No authentication required. Provides detailed information about available tasks,
    their purposes, scheduling, and system requirements.
    
    Returns:
        dict: Complete task system information
    """
    return {
        "system_info": {
            "name": "CryptoPredict Background Task System",
            "version": "1.0.0",
            "technology": "Celery with Redis broker",
            "purpose": "Automated cryptocurrency data collection and processing"
        },
        "available_tasks": {
            "sync_all_prices": {
                "description": "Synchronize current prices for all active cryptocurrencies",
                "schedule": "Every 5 minutes",
                "type": "periodic",
                "estimated_duration": "30-60 seconds",
                "dependencies": ["CoinGecko API", "Database"]
            },
            "sync_historical_data": {
                "description": "Synchronize historical price data for cryptocurrencies", 
                "schedule": "Every hour at minute 0",
                "type": "periodic",
                "estimated_duration": "2-5 minutes",
                "dependencies": ["CoinGecko API", "Database"]
            },
            "discover_new_cryptocurrencies": {
                "description": "Discover and add new cryptocurrencies to the system",
                "schedule": "Daily at 2:00 AM",
                "type": "periodic",
                "estimated_duration": "1-3 minutes",
                "dependencies": ["CoinGecko API", "Database"]
            },
            "cleanup_old_data": {
                "description": "Clean up old price data to manage database size",
                "schedule": "Weekly on Sunday at 3:00 AM", 
                "type": "periodic",
                "estimated_duration": "5-15 minutes",
                "dependencies": ["Database"]
            },
            "sync_specific_cryptocurrency": {
                "description": "Synchronize data for a specific cryptocurrency",
                "schedule": "On demand (manual execution)",
                "type": "manual",
                "estimated_duration": "10-30 seconds",
                "dependencies": ["CoinGecko API", "Database"]
            }
        },
        "system_requirements": {
            "celery_worker": "Required for task execution",
            "celery_beat": "Required for scheduled tasks", 
            "redis": "Required as message broker and result backend",
            "database": "Required for data persistence",
            "external_apis": "CoinGecko API for cryptocurrency data"
        },
        "startup_commands": {
            "start_workers": "./temp/start-celery.sh",
            "worker_only": "celery -A app.tasks.celery_app worker --loglevel=info",
            "beat_only": "celery -A app.tasks.celery_app beat --loglevel=info",
            "flower_monitoring": "celery -A app.tasks.celery_app flower --port=5555"
        },
        "monitoring": {
            "health_endpoint": "/api/v1/tasks/health",
            "status_endpoint": "/api/v1/tasks/status", 
            "schedules_endpoint": "/api/v1/tasks/schedules",
            "flower_ui": "http://localhost:5555 (if running)"
        },
        "management_endpoints": {
            "start_tasks": "POST /api/v1/tasks/start",
            "stop_tasks": "POST /api/v1/tasks/stop",
            "manual_execution": "POST /api/v1/tasks/manual/{task_name}",
            "task_results": "GET /api/v1/tasks/result/{task_id}",
            "revoke_task": "DELETE /api/v1/tasks/revoke/{task_id}"
        },
        "timestamp": datetime.now(timezone.utc).isoformat()
    }